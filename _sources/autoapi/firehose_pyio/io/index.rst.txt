firehose_pyio.io
================

.. py:module:: firehose_pyio.io


Classes
-------

.. autoapisummary::

   firehose_pyio.io.WriteToFirehose


Module Contents
---------------

.. py:class:: WriteToFirehose(delivery_stream_name: str, jsonify: bool, multiline: bool, max_trials: int = 3, append_error: bool = True, failed_output: str = 'write-to-firehose-failed-output', fake_config: dict = {})

   Bases: :py:obj:`apache_beam.PTransform`


   A transform that puts records into an Amazon Firehose delivery stream

   Takes an input PCollection and put them in batch using the boto3 package.
   For more information, visit the `Boto3 Documentation <https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/firehose/client/put_record_batch.html>`__.

   Note that, if the PCollection element is a tuple (i.e. keyed stream), only the value is used to put records in batch.

   :param delivery_stream_name: Amazon Firehose delivery stream name.
   :type delivery_stream_name: str
   :param jsonify: Whether to convert records into JSON.
   :type jsonify: bool
   :param multiline: Whether to add a new line at the end of each record.
   :type multiline: bool
   :param max_trials: Maximum number of trials to put failed records. Defaults to 3.
   :type max_trials: int
   :param append_error: Whether to append error details to failed records. Defaults to True.
   :type append_error: bool, optional
   :param failed_output: A tagged output name where failed records are written to. Defaults to 'write-to-firehose-failed-output'.
   :type failed_output: str, optional
   :param fake_config: Config parameters when using FakeFirehoseClient for testing. Defaults to {}.
   :type fake_config: dict, optional


   .. py:attribute:: delivery_stream_name


   .. py:attribute:: jsonify


   .. py:attribute:: multiline


   .. py:attribute:: max_trials


   .. py:attribute:: append_error


   .. py:attribute:: failed_output


   .. py:attribute:: fake_config


   .. py:method:: expand(pcoll: apache_beam.pvalue.PCollection)


